{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scrapy.selector import Selector\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Scraping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chrome_options = webdriver.ChromeOptions()\n",
    "chrome_options.add_argument('--headless')\n",
    "chrome_options.add_argument('--no-sandbox')\n",
    "chrome_options.add_argument('--disable-dev-shm-usage')\n",
    "driver = webdriver.Chrome(options=chrome_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url = \"https://www.imdb.com/title/tt1517268/reviews/?ref_=tt_ov_rt\"\n",
    "url = \"https://www.imdb.com/title/tt0111161/reviews\"\n",
    "driver.get(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel = Selector(text = driver.page_source)\n",
    "review_counts = sel.css('.lister .header span::text').extract_first().replace(',','').split(' ')[0]\n",
    "print(review_counts)\n",
    "more_review_pages = int(int(review_counts)/25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "# for i in tqdm(range(more_review_pages)):\n",
    "for i in tqdm(range(0,25)):\n",
    "    try:\n",
    "        css_selector = 'load-more-trigger'\n",
    "        driver.find_element(By.ID, css_selector).click()\n",
    "        sleep(10)\n",
    "    except:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wait for up to 10 seconds for the elements to be present\n",
    "wait = WebDriverWait(driver, 10)\n",
    "elements = wait.until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, 'div.review-container')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = driver.find_elements(By.CSS_SELECTOR, 'div.review-container')\n",
    "len(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_list = []\n",
    "review_date_list = []\n",
    "review_title_list = []\n",
    "author_list = []\n",
    "review_list = []\n",
    "review_url_list = []\n",
    "error_url_list = []\n",
    "error_msg_list = []\n",
    "reviews = driver.find_elements(By.CSS_SELECTOR, 'div.review-container')\n",
    "\n",
    "for d in tqdm(reviews):\n",
    "    try:\n",
    "        sel2 = Selector(text = d.get_attribute('innerHTML'))\n",
    "        try:\n",
    "            rating = sel2.css('.rating-other-user-rating span::text').extract_first()\n",
    "        except:\n",
    "            rating = np.NaN\n",
    "        try:\n",
    "            review = sel2.css('.text.show-more__control::text').extract_first()\n",
    "        except:\n",
    "            review = np.NaN\n",
    "        try:\n",
    "            review_date = sel2.css('.review-date::text').extract_first()\n",
    "        except:\n",
    "            review_date = np.NaN\n",
    "        try:\n",
    "            author = sel2.css('.display-name-link a::text').extract_first()\n",
    "        except:\n",
    "            author = np.NaN\n",
    "        try:\n",
    "            review_title = sel2.css('a.title::text').extract_first()\n",
    "        except:\n",
    "            review_title = np.NaN\n",
    "        try:\n",
    "            review_url = sel2.css('a.title::attr(href)').extract_first()\n",
    "        except:\n",
    "            review_url = np.NaN\n",
    "        rating_list.append(rating)\n",
    "        review_date_list.append(review_date)\n",
    "        review_title_list.append(review_title)\n",
    "        author_list.append(author)\n",
    "        review_list.append(review)\n",
    "        review_url_list.append(review_url)\n",
    "    except Exception as e:\n",
    "        print(\"Going in Exception\")\n",
    "        error_url_list.append(url)\n",
    "        error_msg_list.append(e)\n",
    "review_df = pd.DataFrame({\n",
    "    'Review_Date':review_date_list,\n",
    "    'Author':author_list,\n",
    "    'Rating':rating_list,\n",
    "    'Review_Title':review_title_list,\n",
    "    'Review':review_list,\n",
    "    'Review_Url':review_url\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_df.to_csv(\"./reviews.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = review_df\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"./barbie.csv\")\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 1000,### YOUR CODE HERE, # the character length of the chunk\n",
    "    chunk_overlap = 200,### YOUR CODE HERE, # the character length of the overlap between chunks\n",
    "    length_function =len ### YOUR CODE HERE, # the length function - in this case, character length (aka the python len() fn.)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pinecone\n",
    "import os\n",
    "index_name = 'movie-review-index'\n",
    "\n",
    "pinecone.init(\n",
    "    api_key= os.environ['PINECONE_API_KEY'],\n",
    "    environment= os.environ['PINECONE_ENV']\n",
    ")\n",
    "\n",
    "if index_name not in pinecone.list_indexes():\n",
    "    # we create a new index\n",
    "    pinecone.create_index(\n",
    "        name=index_name,\n",
    "        metric='cosine',\n",
    "        dimension= 1536 ### YOU CODE HERE - REMEMBER TO USE THE SAME DIMENSION AS THE EMBEDDING MODEL (text-embedding-ada-002)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 1536,\n",
       " 'index_fullness': 0.0,\n",
       " 'namespaces': {'': {'vector_count': 858}},\n",
       " 'total_vector_count': 858}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = pinecone.GRPCIndex(index_name)\n",
    "\n",
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Caching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.embeddings import CacheBackedEmbeddings\n",
    "from langchain.storage import LocalFileStore\n",
    "\n",
    "store = LocalFileStore(\"./cache/\")\n",
    "\n",
    "core_embeddings_model = OpenAIEmbeddings()\n",
    "\n",
    "embedder = CacheBackedEmbeddings.from_bytes_store(\n",
    "    core_embeddings_model,\n",
    "    store,\n",
    "    namespace= core_embeddings_model.model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "from uuid import uuid4\n",
    "\n",
    "BATCH_LIMIT = 100\n",
    "\n",
    "texts = []\n",
    "metadatas = []\n",
    "\n",
    "for i in tqdm(range(len(data))):\n",
    "\n",
    "    record = data.iloc[i]\n",
    "\n",
    "    metadata = {\n",
    "        'review-url': str(record[\"Review_Url\"]),\n",
    "        'review-date' : str(record[\"Review_Date\"]),\n",
    "        'author' : str(record[\"Author\"]),\n",
    "        'rating' : str(record[\"Rating\"]),\n",
    "        'review-title' : str(record[\"Review_Title\"]),\n",
    "    }\n",
    "\n",
    "    record_texts = text_splitter.split_text(\n",
    "        record[\"Review\"]\n",
    "        )\n",
    "\n",
    "    record_metadatas = [{\n",
    "        \"chunk\": j, \"text\": text, **metadata\n",
    "    } for j, text in enumerate(record_texts)]\n",
    "    texts.extend(record_texts)\n",
    "    metadatas.extend(record_metadatas)\n",
    "    \n",
    "    if len(texts) >= BATCH_LIMIT:\n",
    "        ids = [str(uuid4()) for _ in range(len(texts))]\n",
    "        embeds = embedder.embed_documents(texts)\n",
    "        index.upsert(vectors=zip(ids, embeds, metadatas))\n",
    "        texts = []\n",
    "        metadatas = []\n",
    "\n",
    "if len(texts) > 0:\n",
    "    ids = [str(uuid4()) for _ in range(len(texts))]\n",
    "    embeds = embedder.embed_documents(texts)\n",
    "    index.upsert(vectors=zip(ids, embeds, metadatas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q and A with Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Pinecone\n",
    "\n",
    "text_field = \"text\"\n",
    "\n",
    "index = pinecone.Index(index_name)\n",
    "\n",
    "vectorstore = Pinecone(\n",
    "    index, embedder.embed_query, text_field\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content=\"I really wanted to enjoy this and I know that I am not the target audience but there were massive plot holes and no real flow. The film was very disjointed. Ryan Gosling as good as he is seemed to old to play Ken and Will Ferrell ruined every scene he was in. I just didn't get it, it seemed hollow artificial and hackneyed. A waste of some great talent. It was predictable without being reassuring and trying so hard to be woke in the most superficial way in that but trying to tick so many boxes it actually ticked none. Margo Robbie looks beautiful throughout, the costumes and the sets were amazing but the story was way too weak and didn't make much sense at all.\", metadata={'author': 'agjbull', 'chunk': 0.0, 'rating': '6.0', 'review-date': datetime.datetime(2023, 7, 23, 0, 0), 'review-title': ' Just a little empty\\n', 'review-url': '/review/rw9221648/?ref_=tt_urv'}),\n",
       " Document(page_content=\"because what really matters is the story. Well it fell short on that mark and it was really disappointing. The pacing was horrible, the villain won and was pretty irrelevant in the long run, the story was all over the place, and it is totally not for kids. I think the worst part is how disappointed I was at the opportunity to really make something special and it just wasn't. 6 points for all the laughs and fun I had and I would expect 6-7 to be an appropriate rating.\", metadata={'author': 'andermic18', 'chunk': 1.0, 'rating': '6.0', 'review-date': datetime.datetime(2023, 7, 21, 0, 0), 'review-title': ' No Direction\\n', 'review-url': '/review/rw9221648/?ref_=tt_urv'}),\n",
       " Document(page_content=\"I wanted to like it. But I just didn't. The story wasn't very compelling to me because it seemed as if the entire point of much of the movie was to provide learning moments for viewers with some slapstick comedy and quick-delivery comedy. The story itself should nearly always be more important.\", metadata={'author': 'brianjohnson-20043', 'chunk': 0.0, 'rating': '4.0', 'review-date': datetime.datetime(2023, 7, 24, 0, 0), 'review-title': ' This movie tries to be too much\\n', 'review-url': '/review/rw9221648/?ref_=tt_urv'})]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"I really wanted to enjoy this and I know that I am not the target audience but there were massive plot holes and no real flow.\"\n",
    "\n",
    "vectorstore.similarity_search(\n",
    "    query, \n",
    "    k=3  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "query = \"I really wanted to enjoy this and I know that I am not the target audience but there were massive plot holes and no real flow.\"\n",
    "vectorstore.similarity_search(\n",
    "    query, \n",
    "    k=3  \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q and A Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms.openai import OpenAIChat\n",
    "\n",
    "llm = OpenAIChat(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "retriever = vectorstore.as_retriever()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.callbacks import StdOutCallbackHandler\n",
    "\n",
    "handler = StdOutCallbackHandler()\n",
    "\n",
    "qa_with_sources_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    callbacks=[handler],\n",
    "    return_source_documents=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_with_sources_chain({\"query\" : \"How was Will Ferrell in this movie?\"})[\"result\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_with_sources_chain({\"query\" : \"Do reviewers consider this movie Kenough?\"})[\"result\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = qa_with_sources_chain({\"query\" : \"Was Will Ferrel funny?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in result.items():\n",
    "    print(f\"Key: {k}\")\n",
    "    print(f\"Value: {v}\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for page_content, metadata in result[\"source_documents\"]:\n",
    "    print(f\"Metadata: {metadata}\")\n",
    "    print(f\"Page Content: {page_content}\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tracing with W and B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_with_sources_chain({\"query\" : \"Do reviewers consider this movie Kenough?\"})[\"result\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain\n",
    "from langchain.cache import InMemoryCache\n",
    "langchain.llm_cache = InMemoryCache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "qa_with_sources_chain({\"query\" : \"Do reviewers consider this movie Kenough?\"})[\"result\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "qa_with_sources_chain({\"query\" : \"Do reviewers consider this movie Kenough?\"})[\"result\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "qa_with_sources_chain({\"query\" : \"Do reviewers consider this here movie Kenough?\"})[\"result\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmops",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
